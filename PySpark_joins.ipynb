{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Joins_example').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-M876NKNT:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = [\n",
    "    \n",
    "    {\n",
    "        'key':'abc',\n",
    "        'val1':1.1,\n",
    "        'val2':1.2\n",
    "    },\n",
    "    {\n",
    "        'key':'def',\n",
    "        'val1':3.0,\n",
    "        'val2':3.4\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "dataset2 = [\n",
    "    \n",
    "    {\n",
    "        'key':'abc',\n",
    "        'val1':2.1,\n",
    "        'val2':2.2\n",
    "    },\n",
    "    {\n",
    "        'key':'xyz',\n",
    "        'val1':3.1,\n",
    "        'val2':3.2\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize(dataset1)\n",
    "df1 = spark.createDataFrame(rdd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.parallelize(dataset2)\n",
    "df2 = spark.createDataFrame(rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+\n",
      "|key|val1|val2|\n",
      "+---+----+----+\n",
      "|abc| 1.1| 1.2|\n",
      "|def| 3.0| 3.4|\n",
      "+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+\n",
      "|key|val1|val2|\n",
      "+---+----+----+\n",
      "|abc| 2.1| 2.2|\n",
      "|xyz| 3.1| 3.2|\n",
      "+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner join\n",
    "The inner join selects matching records from both of the dataframes. Match is performed on column(s) specified in the on parameter. In this example, both dataframes are joined when the column named key  has same value, i.e. 'abc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+----+\n",
      "|key|val1|val2|val1|val2|\n",
      "+---+----+----+----+----+\n",
      "|abc| 1.1| 1.2| 2.1| 2.2|\n",
      "+---+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_inner = df1.join(df2, on=['key'], how='inner')\n",
    "df_inner.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Join\n",
    "Outer join combines data from both dataframes, irrespective of 'on' column matches or not. If there is a match combined, one row is created if there is no match missing columns for that row are filled with null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+----+\n",
      "|key|val1|val2|val1|val2|\n",
      "+---+----+----+----+----+\n",
      "|xyz|null|null| 3.1| 3.2|\n",
      "|abc| 1.1| 1.2| 2.1| 2.2|\n",
      "|def| 3.0| 3.4|null|null|\n",
      "+---+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outer = df1.join(df2, on =['key'], how ='outer')\n",
    "df_outer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Join\n",
    "Left join will choose all the data from the left dataframe (i.e. df1 in this example) and perform matches on column name key. If a match is found, values are filled from the matching row, and if not found, unavailable values are filled with null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+----+\n",
      "|key|val1|val2|val1|val2|\n",
      "+---+----+----+----+----+\n",
      "|abc| 1.1| 1.2| 2.1| 2.2|\n",
      "|def| 3.0| 3.4|null|null|\n",
      "+---+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_left = df1.join(df2, on=['key'], how='left')\n",
    "df_left.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Join\n",
    "This is the same as the left join operation performed on right side dataframe, i.e df2 in this example.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+----+\n",
      "|key|val1|val2|val1|val2|\n",
      "+---+----+----+----+----+\n",
      "|xyz|null|null| 3.1| 3.2|\n",
      "|abc| 1.1| 1.2| 2.1| 2.2|\n",
      "+---+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_right = df1.join(df2, on = ['key'], how='right')\n",
    "df_right.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Semi Join\n",
    "This is like inner join, with only the left dataframe columns and values are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+\n",
      "|key|val1|val2|\n",
      "+---+----+----+\n",
      "|abc| 1.1| 1.2|\n",
      "+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_left_semi = df1.join(df2, on=['key'], how='left_semi')\n",
    "df_left_semi.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
